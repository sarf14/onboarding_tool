// Page content extracted from the onboarding site
// Content cleaned of headers and navigation elements

export const pageContent: Record<number, string> = {
  1: `What You Will Do

There is a client model that performs tasks based on the given prompt.
The model goes through different websites, checking and performing actions as required by the task.
It completes the process step-by-step, starting with its thoughts (what it plans to do next) and continuing through actions until it concludes with a final output.
• During this step-by-step execution, the model might make mistakes or errors in its reasoning or actions.
• These mistakes can cause the trajectory to divert from the correct path, leading to task failure.

Your role as an annotator is to:
• Review the entire trajectory of the model (its thoughts and actions).
• Identify where the error happened and what type of error it is using the Error Categorization (EC) document.
• Mark the main cause of failure — the specific error that led the model to go wrong.
• If the model succeeded, ensure the process was correct and complete.
• If it failed, find and label the exact reason for failure, not just the symptoms.

The goal is to make sure that each model trajectory is evaluated correctly, so that the model can be improved and retrained based on your feedback.

Understanding your role as an annotator is crucial for model improvement.`,

  2: `Reading the Error Categorization Doc
Why You Should Read the EC Example Library

The EC Example Library explains all the error types a model can make while performing a task.
It helps you learn how to identify and mark errors correctly during annotation.

The document includes:
➤ Definitions of each error
➤ Key points to check before marking
➤ Examples of correct and incorrect cases

It covers all the main areas from
Prompt Errors,
Incorrect / Missed Model Actions,
Incorrect / Missed Model Thoughts,
Output errors,
Infrastructure Errors(Non-Model Fault Errors), Tool Error

Reading it will help you make accurate, consistent, and confident decisions while evaluating model trajectories.

The EC Example Library is your most important reference document.`,

  3: `Cases
Depending on the task, error, and model's output, you have to decide the final conclusion of the task.

There are four possible cases:

1. Success - Task completed correctly.

2. Failure - Task not completed or result incorrect.

3. Cannot Be Determined - Task can't be verified due to missing or outdated info.

4. Accidental Success – Correct result but achieved by chance or wrong reasoning.

These are the four possible outcomes for any task.`,

  4: `Task Status Definitions
Task Status | Definition | An efficient way of writing a status explanation

FAILURE:
The prompt requirements are not met. The model's summary includes incorrect, hallucinated, or misleading information or links. Any mistake in the output must result in marking this as a failure. When the model says, 'it couldn't do the process, mark the task as failure'

• Clearly state the number of results returned by the model (if applicable)
• Explain how the identified error(s) impacted the model's trajectory and final output.
• Highlight the discrepancy between the model output and manual verification.
• End with a conclusive statement confirming the task is a "Failure".

SUCCESS:
The prompt requirements are fully satisfied. The content in the summary is completely accurate and verifiable.

• Mention the number of results generated by the model (if applicable).
• Briefly explain how the model fulfilled the prompt requirements.
• Support the result using manual verification evidence.
• End with a conclusive statement confirming the task is a "Success".

ACCIDENTAL SUCCESS:
Cases where the model returns zero results without conducting thorough research or following the expected trajectory, but manual verification confirms that zero results are indeed the correct answer.

• Mention that the model gave 0 results
• Briefly explain how the model failed to follow the expected reasoning or action steps.
• Explain how manual verification confirms the absence of results.
• Conclusive statement confirming the task is an "Accidental Success".

CANNOT BE DETERMINED:
Applicable when the prompt contains requirements that the model cannot fulfill due to technical limitations or ambiguity. Common scenarios include: prompts requiring audio/video interpretation, booking tickets for past events, logging into private accounts, or when the prompt lacks sufficient clarity.

• Mention the number of results, if any, returned by the model
• Briefly explain why the prompt is unanswerable or ambiguous
• Reference manual verification to confirm the task is indeterminate
• Conclusive statement confirming the task status is "Cannot be determined"

• If the prompt is bad, this default cannot be determined

Clear status definitions help maintain consistency across evaluations.`,

  5: `What is Critical Error
• A Critical Error is the main mistake that caused the model to fail the task.
• It is the root cause of the failure — the step where things actually went wrong.
• Even if multiple small errors are present, you must find and mark the one key error that directly led to the task failure.
• Identifying the correct critical error helps ensure accurate evaluation and a clear understanding of why the model failed.
• Critical Error can be one or more than one
• Critical Error is same as the primary error (Both are same)

Finding the critical error is key to accurate model evaluation.`,

  6: `Trajectory Status
• The Trajectory Status represents the overall quality of the model's process (all steps except the final one).

Marking Rules:

• If Task Status = Success → Select Success

• If Task Status = Cannot be Determined → Select Cannot be Determined

• If Task Status = Failure →
○ If the critical error is in the last step only (for example, Summarization Failure or Dissatisfactory Output),
→ Mark the Trajectory Status as "Success".
○ If the critical error occurs anywhere in the middle or earlier part of the trajectory (i.e., during process steps and not in the final step),
→ Mark the Trajectory Status as "Failure".

Trajectory status depends on where the error occurred in the process.`,

  7: `Auto Eval
AutoEval (Automatic Evaluation) is a system that automatically reviews model outputs using predefined rules and logic.

It helps to speed up evaluations by predicting whether a model's output is Success or Failure.

AutoEval checks things like:
• If the model met the main task requirements.
• If key information is missing or incorrect.
• If the final output format or reasoning is wrong.

However, AutoEval is not always 100% accurate — it can miss context or misunderstand certain cases.

That's why human annotators still review each task to verify or correct AutoEval's decision.

If the annotator's judgment disagrees with AutoEval, they must recheck carefully and provide reasoning for their decision.

Always verify AutoEval's decisions - human judgment is essential.`,

  8: `Moving Towards Practical Understanding
Now that you've learned the basics about the platforms, documentation, and key terms, Let's move to the actual example to understand how everything works together — step by step.

In this part, you'll see:
1. How a task or prompt is given to the model.
2. How the model performs actions and generates steps (the trajectory).
3. How you, as an annotator, review those steps and identify if any errors occurred.
4. How to mark the critical error, decide the task status, and assign the trajectory status.

This walkthrough will help you understand the complete flow of annotation — from model execution to final evaluation.

Understanding the complete flow helps you become a better annotator.`,

  9: `Video 1: Introduction To Encord and Yutori Platforms
This video gives a brief introduction to the Yutori and Encord platforms.
• You will learn what each platform is used for and how they work together in the annotation process.
• It explains:
○ The purpose of both platforms.
○ How to navigate through them.
○ Basic functions like viewing trajectories, marking errors, and submitting evaluations.

Goal:
By the end of this video, you'll understand the role of Yutori and Encord in model evaluation and how to use them effectively during annotation.

Watch this tutorial to see the annotation platform in action.`,

  10: `Video 2: Reviewing Process For Autonex QC
This video explains the step-by-step review process followed in Autonex QC.
• You will learn how to check annotations, verify marked errors, and ensure quality and consistency in evaluations.
• It covers:
○ How to open and review trajectories.
○ How to confirm or correct the annotator's marked errors.
○ What to look for during Quality Check (QC) — accuracy, reasoning, and alignment with the EC guidelines.

Goal:
By the end of this video, you'll understand how to perform quality checks in Autonex, maintain annotation standards, and provide clear feedback to annotators.

Follow this QC process to ensure quality and consistency.`,

  11: `Video 3: Finding the Critical Error & Pro Tips
Video 3 Finding the Critical Error:
This video explains how to identify the Critical Error in a model's trajectory.
• You will learn how to trace where the model went wrong and find the main mistake that caused the task to fail.
• It covers:
○ How to review the model's thoughts and actions step-by-step.
○ How to spot the exact step where the model diverged from the correct path.
○ How to confirm the Critical Error using the Error Categorization (EC) Library.
○ How to use the Ctrl+F function to verify the error mistake

Goal:
By the end of this video, you'll know how to track and mark the Critical Error accurately, ensuring each failure is classified based on its true cause.

Pro tips
• Task status reasoning and Primary error should be linked (if failure was broken link, find out where the broken link entered the trajectory)
• You are detectives, playing against AI and finding its faults. So need to do it intelligently
• Read the Error Categories document if you have any doubts. Or directly ask the doubts group!
• The yutori platform sometimes doesn't load - use VPN! - setting it to UK
• We work as reviewers, so we need to build that mindset (what value does a reviewer add?)

Apply these pro tips and learn to find the true cause of failure.`
};

// Page URL mapping
export const pageUrls: Record<number, string> = {
  1: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=1',
  2: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=2',
  3: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=3',
  4: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=4',
  5: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=5',
  6: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=6',
  7: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=7',
  8: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=8',
  9: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=9',
  10: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=10',
  11: 'https://autonex-onboard.vercel.app/OnboardingDoc?page=11'
};
